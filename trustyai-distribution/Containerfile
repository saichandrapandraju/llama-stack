# WARNING: This file is auto-generated. Do not modify it manually.
# Generated by: trustyai-distribution/build.py

FROM registry.access.redhat.com/ubi9/python-312:latest
WORKDIR /opt/app-root

# Switch to root for package installation
USER root
RUN pip install sqlalchemy # somehow sqlalchemy[asyncio] is not sufficient
RUN pip install \
    aiosqlite \
    autoevals \
    chardet \
    datasets \
    fastapi \
    fire \
    garak==0.12.0 \
    httpx \
    kubernetes \
    llama_stack_provider_lmeval==0.1.7 \
    llama_stack_provider_trustyai_fms==0.1.4 \
    llama_stack_provider_trustyai_garak==0.1.1 \
    matplotlib \
    mcp>=1.8.1 \
    nltk \
    numpy \
    openai \
    opentelemetry-exporter-otlp-proto-http \
    opentelemetry-sdk \
    pandas \
    pillow \
    psycopg2-binary \
    pymilvus \
    pymongo \
    pypdf \
    redis \
    requests \
    scikit-learn \
    scipy \
    sentencepiece \
    sqlalchemy[asyncio] \
    tqdm \
    transformers \
    uvicorn
RUN pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
RUN pip install --no-deps sentence-transformers
RUN pip install --no-cache llama-stack==0.2.16

# Switch back to non-root user
USER 1001
RUN mkdir -p ${HOME}/.llama/providers.d ${HOME}/.cache
COPY trustyai-distribution/run.yaml ${APP_ROOT}/run.yaml
COPY trustyai-distribution/providers.d/ ${HOME}/.llama/providers.d/

ENTRYPOINT ["python", "-m", "llama_stack.distribution.server.server", "--config", "/opt/app-root/run.yaml"]
